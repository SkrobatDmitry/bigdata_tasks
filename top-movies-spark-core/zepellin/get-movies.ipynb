{
  "metadata": {
    "name": "top-movies-spark-core",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%sh\n\nfunction load_dataset() {\n  wget -q https://files.grouplens.org/datasets/movielens/$1.zip\n  unzip -u -q $1.zip $1/movies.csv $1/ratings.csv\n\n  if [ -d dataset ]; then\n    rm -r dataset\n  fi\n\n  mv $1 dataset\n  rm $1.zip\n}\n\ndataset\u003d\"ml-latest-small\"\nhdfs_path\u003d\"/top-movies-spark-core\"\n\nload_dataset $dataset\n\nhdfs dfs -test -d $hdfs_path\nif [ $? -eq 0 ]; then\n  hdfs dfs -rm -r $hdfs_path \u0026\u003e/dev/null\nfi\n\nhdfs dfs -mkdir $hdfs_path\nhdfs dfs -put dataset $hdfs_path"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n\nimport sys\nimport re\nfrom itertools import islice\nfrom pyspark import rdd"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n\ndataset_path \u003d \"/top-movies-spark-core/dataset\"\noutput_path \u003d \"/top-movies-spark-core/output\"\n\nargs \u003d {\n    \u0027N\u0027: 3,\n    \u0027regexp\u0027: \u0027\u0027,\n    \u0027year_from\u0027: 0,\n    \u0027year_to\u0027: 10000,\n    \u0027genres\u0027: None\n}"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\r\n\r\ndef get_rdd_from_csv(path: str, is_header: bool \u003d True) -\u003e rdd:\r\n    try:\r\n        lnd_rdd \u003d sc.textFile(path)\r\n        return lnd_rdd.mapPartitionsWithIndex(lambda i, it: islice(it, 1, None) if i \u003d\u003d 0 else it) if is_header else lnd_rdd\r\n    except Exception as e:\r\n        print(e, file\u003dsys.stderr)\r\n        \r\n\r\nraw_movies_rdd \u003d get_rdd_from_csv(f\u0027{dataset_path}/movies.csv\u0027)\r\nraw_ratings_rdd \u003d get_rdd_from_csv(f\u0027{dataset_path}/ratings.csv\u0027)\r\n\r\nprint(raw_movies_rdd.take(3))\r\nprint(raw_ratings_rdd.take(3))"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n\ndef get_movie_tuples(movie_line: str) -\u003e list:\n        try:\n            movie_id, title, genres \u003d re.split(\u0027,(?\u003d(?:[^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\u0027, movie_line)\n            title \u003d title[1:-1] if title.startswith(\u0027\"\u0027) and title.endswith(\u0027\"\u0027) else title\n\n            movie_title, movie_year \u003d re.findall(\u0027(.*)[ ]\\((\\d{4})\\)$\u0027, title)[0]\n\n            return [(int(movie_id), (movie_title, int(movie_year), movie_genre)) for movie_genre in genres.split(\u0027|\u0027)]\n        except Exception:\n            return []\n            \n\npreprocessed_movies_rdd \u003d raw_movies_rdd.flatMap(get_movie_tuples)\nprint(preprocessed_movies_rdd.take(3))"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n\ndef match_genre(genre: str, genres: str) -\u003e bool:\n    return genre.lower() in genres.lower() if genres else genre !\u003d \u0027(no genres listed)\u0027\n    \n    \ndef match_title(title: str, regexp: str) -\u003e bool:\n    return bool(re.search(regexp, title, re.IGNORECASE))\n\n\ndef match_year(year: int, year_from: int, year_to: int) -\u003e bool:\n    return year_from \u003c\u003d year \u003c\u003d year_to\n\n\ndef match_movie(movie_tuple: tuple) -\u003e bool:\n    movie_id, movie \u003d movie_tuple\n    movie_title, movie_year, movie_genre \u003d movie\n    \n    return match_genre(movie_genre, args[\u0027genres\u0027]) and match_title(movie_title, args[\u0027regexp\u0027]) and match_year(movie_year, args[\u0027year_from\u0027], args[\u0027year_to\u0027])\n    \n\nmovies_rdd \u003d preprocessed_movies_rdd.filter(match_movie)\nprint(movies_rdd.take(3))"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n\ndef get_rating_tuple(rating_line: str) -\u003e tuple:\n    try:\n        _, movie_id, rating, _ \u003d rating_line.split(\u0027,\u0027)\n        return int(movie_id), [float(rating), 1]\n    except Exception:\n        return ()\n        \n\npreprocessed_ratings_rdd \u003d raw_ratings_rdd.map(get_rating_tuple)\nprint(preprocessed_ratings_rdd.take(3))"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n\ndef combine_rating(first_rating_tuple: tuple, second_rating_tuple: tuple) -\u003e tuple:\n    first_rating, first_amount \u003d first_rating_tuple\n    second_rating, second_amount \u003d second_rating_tuple\n    return first_rating + second_rating, first_amount + second_amount\n    \n\ncombined_ratings_rdd \u003d preprocessed_ratings_rdd.reduceByKey(combine_rating)\nprint(combined_ratings_rdd.take(3))"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n\ndef get_average_rating(rating_tuple: tuple) -\u003e float:\n    rating, amount \u003d rating_tuple\n    return round(rating / amount, 4)\n\n    \nratings_rdd \u003d combined_ratings_rdd.mapValues(get_average_rating)\nprint(ratings_rdd.take(3))"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n\n\ndef reorganize_tuple(joint_tuple: tuple) -\u003e tuple:\n    movie_id, movie_rating_tuple \u003d joint_tuple\n\n    movie_tuple, movie_rating \u003d movie_rating_tuple\n    movie_title, movie_year, movie_genre \u003d movie_tuple\n\n    return movie_genre, (movie_title, movie_year, movie_rating)\n    \n\npreprocessed_movies_ratings_rdd \u003d movies_rdd.join(ratings_rdd).map(reorganize_tuple)\nprint(preprocessed_movies_ratings_rdd.take(3))"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n\ndef get_top_n_values(movie_rating_tuples: list) -\u003e list:\n    movie_rating_tuples.sort(key\u003dlambda x: (-x[2], -x[1], x[0]))\n    return movie_rating_tuples[:args[\u0027N\u0027]] if args[\u0027N\u0027] else movie_rating_tuples\n\ngrouped_movies_ratings_rdd \u003d preprocessed_movies_ratings_rdd.groupByKey().sortByKey()\nmovies_ratings_rdd \u003d grouped_movies_ratings_rdd.mapValues(lambda v: get_top_n_values(list(v)))\n\nfor group in movies_ratings_rdd.take(3):\n    print(group)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n\ndef get_csv_list(key_value_pair: tuple, separator: str \u003d \u0027,\u0027) -\u003e list:\n    \n    def get_escaped_value(value: str, escape_char: str \u003d \u0027\"\u0027) -\u003e str:\n        return value.center(len(value) + 2, escape_char) if separator in value else value\n\n    genre, movies \u003d key_value_pair\n    return [f\u0027{genre}{separator}{get_escaped_value(title)}{separator}{year}{separator}{rating}\u0027 for title, year, rating in movies]\n\n\ndef get_csv_rdd(movies_ratings_rdd: rdd, header: str) -\u003e rdd:\n    csv_rdd \u003d movies_ratings_rdd.flatMap(get_csv_list)\n    return sc.parallelize([header]).union(csv_rdd) if header else csv_rdd\n    \n\ncsv_rdd \u003d get_csv_rdd(movies_ratings_rdd, \u0027genre,title,year,rating\u0027)\nprint(csv_rdd.take(3))"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n\ncsv_rdd.saveAsTextFile(output_path)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%sh\n\nhdfs dfs -ls /top-movies-spark-core/output"
    }
  ]
}